---
title: "GWAS for fitness in Drosophila"
output:
  html_document: default
  html_notebook: default
---

```{r message=FALSE, warning=FALSE, results="hide"}
library(dplyr)
library(ggplot2)
library(ggdendro)
library(glue)
library(bigsnpr) # to install:   devtools::install_github("privefl/bigsnpr")
library(readr)
library(pander)
library(future.apply) # for parallel code

# Load the predicted line means, as calculated by get_predicted_line_means
predicted_line_means <- read_csv("data/derived/predicted_line_means.csv")

# Load the wolbachia infection status data from the DGRP website
wolbachia <- read_csv("data/input/wolbachia.csv") %>% 
  mutate(line = paste("line", line, sep = ""))

# Load the chomosomal inversion data from the DGRP website
# these are the 5 inversions that Huang et al. PNAS corrected for
inversions <- read_csv("data/input/inversion genotypes.csv") %>%
    mutate(line = paste("line", line, sep = "")) %>%
    select(line, `In(2L)t`, `In(2R)NS`, `In(3R)P`, `In(3R)K`, `In(3R)Mo`) 

# helper function to pass commands to the terminal
# Note that we set `intern = TRUE`, and pass the result of `system()` to `cat()`, 
# ensuring that the Terminal output will be printed in this knitr report. 
run_command <- function(shell_command, wd = getwd(), path = ""){
  cat(system(glue("cd ", wd, path, "\n",shell_command), intern = TRUE), sep = '\n')
}
```


## Perform SNP quality control and imputation

We cleaned up the DGRP's .bed/.bim/.fam files (available from the [Mackay lab website](http://dgrp2.gnets.ncsu.edu/)) as follows:

1. Remove any SNPs for which genotypes are missing for >10% of the DGRP lines. We then use the software [Beagle](https://faculty.washington.edu/browning/beagle/beagle.html) to impute the remaining missing genotypes.
2. Remove SNPs with a minor allele frequency of less than 5%

Note that in the PLINK-formatted genotype files, lines fixed for the major allele are coded as 2, and lines fixed for the minor allele as 0. This means that in the association tests we calculate, negative effect sizes mean that the minor allele is associated with lower fitness, while positive effect sizes means that the minor allele is associated with higher fitness.

```{r QC_and_imputation, results='hide'}
# Download a copy of PLINK and Beagle
plink  <- bigsnpr::download_plink()
beagle <- bigsnpr::download_beagle()


perform_SNP_QC_and_imputation <- function(phenotypes){
  
  if("block" %in% names(phenotypes)) phenotypes <- phenotypes %>% select(-block)
  
  # Make a list of the lines in our sample and save as a text file for passing to PLINK
  lines_to_keep <- gsub("_", "", phenotypes$line) %>% cbind(.,.)
  write.table(lines_to_keep, row.names = FALSE, col.names = FALSE, file = "data/derived/lines_to_keep.txt", quote = FALSE)
  
  # Define a function to add out phenotype data to a .fam file, which is needed for GWAS analysis and to make sure PLINK includes these samples
  # The 'phenotypes' data frame needs to have a column called 'line'
  add_phenotypes_to_fam <- function(filepath, phenotypes){
    read_delim(filepath, col_names = FALSE, delim = " ") %>% 
      select(X1, X2, X3, X4, X5) %>% # Get all the non-phenotype columns
      left_join(phenotypes %>% mutate(line = gsub("_", "", line)), 
                by = c("X1" = "line")) %>%
      write.table(file = filepath, 
                  col.names = FALSE, row.names = FALSE, 
                  quote = FALSE, sep = " ")
  }
  
  # Use Plink to clean and subset the DGRP's SNP data as follows:
  # Only keep SNPs for which at least 90% of DGRP lines were successfully genotyped (--geno 0.1)
  # Only keep SNPs with a minor allele frequency of 0.05 or higher (--maf 0.05)
  # Finally, write the processed BIM/BED/FAM files to the data/derived directory
  run_command(glue("{plink} --bfile dgrp2",
                          " --geno 0.1 --maf 0.05 --allow-no-sex", 
                          " --make-bed --out ../derived/dgrp2_QC_all_lines"), path = "/data/input/")
  
  # Use the shell command 'sed' to remove underscores from the DGRP line names in the .fam file (e.e. 'line_120' becomes 'line120')
  # Otherwise, these underscores cause trouble when we need to convert from PLINK to vcf format (vcf format uses underscore as a separator)
  for(i in 1:2) run_command("sed -i '' 's/_//' dgrp2_QC_all_lines.fam", path = "/data/derived/")
  
  # Now impute the missing genotypes using Beagle
  # This part uses the data for the full DGRP panel of >200 lines, to infer missing genotypes as accurately as possible. 
  # This step uses a lot of memory (I set to 28MB max, and it used 26.5GB), but maybe it can also run on a less powerful computer?
  # The bigsnpr package provides a helpful wrapper for Beagle called snp_beagleImpute(): it translates to a VCF file and back again using PLINK
  snp_beagleImpute(beagle, plink, "data/derived/dgrp2_QC_all_lines", 
                   ncores = 7, 
                   memory.max = 20, "data/derived/dgrp2_QC_all_lines")
  
  # Again using sed, assign a sex of 'female' to all the DGRP lines (Beagle removed it, and it seems PLINK needs individuals to have a sex in order to work)
  run_command("sed -i '' 's/	0	0	0/	0	0	2/' dgrp2_QC_all_lines.fam", path = "/data/derived/")
  
  # Re-write the .bed file, to make sure the MAF threshold and minor/major allele designations are correctly assigned post-Beagle
  run_command(glue("{plink} --bfile dgrp2_QC_all_lines",
                          " --geno 0.1 --maf 0.05 --allow-no-sex", 
                          " --make-bed --out dgrp2_QC_all_lines"), path = "/data/derived/")
  unlink(list.files("data/derived", pattern = "~", full.names = TRUE)) # delete the original files, which were given a ~ file name by PLINK
  
  # Use PLINK to get the allele IDs and calculate the MAFs across the whole DGRP, for all SNPs that survived QC
  run_command("{plink} --bfile dgrp2_QC_all_lines --freq", path = "/data/derived")
  
  # file.copy("data/derived/dgrp2_QC_all_lines.bed", "data/derived/dgrp2_QC_all_lines_copy.bed")
  # file.copy("data/derived/dgrp2_QC_all_lines.bim", "data/derived/dgrp2_QC_all_lines_copy.bim")
  # file.copy("data/derived/dgrp2_QC_all_lines.fam", "data/derived/dgrp2_QC_all_lines_copy.fam")
  
  # Now cull the PLINK files to just the lines that we measured, and re-apply the MAF cut-off of 0.05 for the new smaller sample of DGRP lines
  run_command(glue("{plink} --bfile dgrp2_QC_all_lines",
                   " --keep-allele-order", # NB: we force PLINK to retain the major and minor allele designations that were defined for the DGRP as a whole! Important for interpretation
                   " --keep lines_to_keep.txt --geno 0.1 --maf 0.05", 
                   " --make-bed --out dgrp2_QC_focal_lines"), path = "/data/derived/")

  # edit the new FAM file to add the phenotype data from 'phenotypes'
  add_phenotypes_to_fam("data/derived/dgrp2_QC_focal_lines.fam", phenotypes)
  
  # Clean up:
  unlink(c("data/derived/lines_to_keep.txt", "data/derived/plink.log"))
}

perform_SNP_QC_and_imputation(phenotypes = predicted_line_means)
```




## Run GWAS using GEMMA

### Create a file of _Wolbachia_ infection status

GEMMA requires that the "covariate" file be in a specific format. Each row needs to match an individual (i.e. a DGRP line) in the PLINK file, and the order should be the same. Each column is one of the covariates. To fit an intercept in addition to the covariates, there should be a column of 1s. Thus, here we make a two-column tsv file wiht the intercept in column 1, and the _Wolbachia_ infection status (a y or a n) in column 2. We elected not to fit the presence/absence of the major inversions (as in sometimes done in studies of the DGRP), since that seems like a trait that will already be captured by the decomposed eigenvectors of the SNP data (since inversions create a block of linked SNPs).

```{r}
# Get the lines for the coming GWAS from the FAM file
lines_in_fam <- read_delim("data/derived/dgrp2_QC_focal_lines.fam", 
                           col_names = FALSE, delim = " ") %>% 
  select(X1) %>% rename(line = X1)

# merge in the covariates: the intercept, the Wolbachia, and the Inversion genotypes
covariates <- left_join(lines_in_fam, wolbachia, by = "line") %>%
  left_join(inversions %>%
              rename(Inv_1 = `In(2L)t`,
                     Inv_2 = `In(2R)NS`,
                     Inv_3 = `In(3R)P`,
                     Inv_4 = `In(3R)K`,
                     Inv_5 = `In(3R)Mo`), by = "line") %>%
  mutate(intercept = 1,
         wolbachia = as.numeric(ifelse(wolbachia == "y", 1, 0))) %>% 
  select(intercept, wolbachia, Inv_1, Inv_2, Inv_3, Inv_4, Inv_5)
  
write_delim(covariates, path = "data/derived/covariate_file_for_GEMMA.txt", col_names = FALSE)
```

### Decompose the genomic relatedness matrix
This step is needed as a set up for the mixed model association tests, which use the eigenvectors and values of the GRM to adjust for 'population structure' among our samples. 

```{r decompose}
# Any command with {bed} uses this particular PLINK file, double-checking that all the SNPs have MAF > 0.05
bed <- "dgrp2_QC_focal_lines -maf 0.05" 

# Calculate the centered GRM for the focal lines
run_command("gemma -bfile {bed} -r2 0.99 -c covariate_file_for_GEMMA.txt -gk 1 -o GRM", path = "/data/derived") 

# Perform decomposition of the GRM, and save its eigenvalues and eigenvectors
run_command("gemma -bfile {bed} -r2 0.99 -c covariate_file_for_GEMMA.txt -k ./output/GRM.cXX.txt -eigen -o eigen_decomp", path = "/data/derived") 

# Remove eigen vectors + values for which the eigenvalue is close to zero, and save the modified file
values <- read_tsv("data/derived/output/eigen_decomp.eigenD.txt", col_names = "eigenvalue")$eigenvalue
vectors <- read_tsv("data/derived/output/eigen_decomp.eigenU.txt", col_names = FALSE)

vectors <- vectors[,-(which(values < 0.2))]
values <- values[-(which(values < 0.2))]
write_tsv(vectors, path = "data/derived/output/eigen_decomp.eigenU.txt", col_names = FALSE)
write_tsv(data.frame(value = values), path = "data/derived/output/eigen_decomp.eigenD.txt", col_names = FALSE)

# Define the paths to the eigenvalues and eigenvectors
GRM <- "-d ./output/eigen_decomp.eigenD.txt -u ./output/eigen_decomp.eigenU.txt"
```


### Run univariate and multivariate association tests

The following code chunk runs 5 linear mixed models in parallel, implemented in the command line software [GEMMA](http://www.xzlab.org/software/GEMMAmanual.pdf). Each of the univariate linear mixed models uses the decomposed genomic relatedness matrix from above, and has one of our four fitness traits as the response variable. The multivariate model contains all four traits, and also used the decomposed genomic relatedness matrix.

```{r run_gwas, results='hide', eval=FALSE}
options(future.globals.maxSize = 2000 * 1024 ^ 2)
plan("multicore")

# The option "-lmm 1" runs a linear mixed model using Wald test to get the p-values
# The option "-r2 0.95" only keeps SNPs that are <95% correlated with Wolbachia infection status
# The option "-c covariate_file_for_GEMMA.txt" adds in the Wolbahia infection status as a covariate, and also tells the model to fit an intercept
opts <- "-lmm 1 -r2 0.99 -c covariate_file_for_GEMMA.txt"

# Run all five GWASs in parallel
c("gemma -bfile {bed} {GRM} {opts} -n 1 -o female_early_lmm",
  "gemma -bfile {bed} {GRM} {opts} -n 2 -o female_late_lmm",
  "gemma -bfile {bed} {GRM} {opts} -n 3 -o male_early_lmm",
  "gemma -bfile {bed} {GRM} {opts} -n 4 -o male_late_lmm",
  "gemma -bfile {bed} {GRM} {opts} -n 1 2 3 4 -o all_four_traits") %>%
  future_lapply(run_command, path = "/data/derived")
```


### Inspect the GEMMA log files from the association tests {.tabset}

According to the GEMMA manual, GEMMA calculates the relatedness matrix from the SNP data, then "extracts the matrix elements corresponding to the analyzed individuals (which may be smaller than the number of total individuals), centers the matrix, and then performs an eigendecomposition". The aim is to better estimate the effects of each SNP independently of the rest of the genome. 

#### Female early-life fitness
```{r lmm1}
cat(readLines("data/derived/output/female_early_lmm.log.txt"), sep = "\n")
```

#### Male early-life fitness
```{r lmm2}
cat(readLines("data/derived/output/male_early_lmm.log.txt"), sep = "\n")
```

#### Female late-life fitness
```{r lmm3}
cat(readLines("data/derived/output/female_late_lmm.log.txt"), sep = "\n")
```

#### Male late-life fitness
```{r lmm4}
cat(readLines("data/derived/output/male_late_lmm.log.txt"), sep = "\n")
```

#### All four traits in MV model
```{r}
cat(readLines("data/derived/output/all_four_traits.log.txt"), sep = "\n")
```


### Add the allele IDs and minor allele frequencies (MAFs) to variant annotation database

This part uses the full DGRP panel, because our aim is to determine how common these alleles are in the original wild population from which the DGRP was captured. These MAFs are the ones used in our statistical analyses and plots.

```{r get_MAF}
# Extract and save the MAFs
MAFs <- read.table("data/derived/plink.frq", header = TRUE, stringsAsFactors = FALSE) %>% 
  mutate(position = map_chr(strsplit(SNP, split = "_"), function(x) x[2])) %>%
  select(SNP, position, MAF, A1, A2) %>% 
  rename(minor_allele = A1,
         major_allele = A2) 

# Connect to the annotation database
db <- src_sqlite("data/derived/annotations.sqlite3", create = TRUE)

MAFs <- tbl(db, "variants") %>% 
  select(SNP, FBID, site.class, distance.to.gene, chr) %>% collect() %>%
  full_join(MAFs, by = "SNP") %>%
  filter(!is.na(MAF)) %>%
  mutate(site.class = replace(site.class, is.na(site.class), "INTERGENIC"))

# Delete the original variant annotation table from the db, and add the new one back in
db$con %>% db_drop_table(table = "variants") 
db %>% copy_to(MAFs, 
               "variants", temporary = FALSE, 
               indexes = list("SNP", "FBID", "chr", "site.class")) 
rm(MAFs)
```



### Clean up the multivariate GEMMA results
```{r clean_up}
read_tsv("data/derived/output/all_four_traits.assoc.txt") %>% 
  rename(SNP = rs,
         female_early = beta_1, 
         female_late  = beta_2,
         male_early   = beta_3, 
         male_late    = beta_4) %>%
  select(-chr, -ps, -n_miss, -allele1, -allele0, -af) %>%
  arrange(p_wald) %>% mutate(fdr = p.adjust(p_wald, method = "BH")) %>%
  write_tsv("data/derived/output/all_four_traits.assoc.txt")

read_tsv("data/derived/output/all_four_traits.assoc.txt") %>% select(SNP, contains("male"), p_wald, fdr)
```

### Perform SNP clumping using PLINK

```{r}
do_snp_clumping <- function(trait){
  run_command(glue("{plink} --bfile dgrp2_QC_focal_lines", 
                   " --clump output/{trait}.assoc.txt",
                   " --clump-field p_wald --clump-p1 0.00001"), # Each clump must contain one snp with p < 10 ^ -5
              path = "/data/derived")
  trait <- gsub("_lmm", "", trait)
  file_name <- glue("data/derived/{trait}_SNP_clumps.txt")
  file.rename("data/derived/plink.clumped", file_name)
  
  clumps <- read.table(file_name, header = TRUE) %>% 
    rename(index_SNP = SNP,
           index_SNP_p_value = P,
           num_SNPs_in_clump = TOTAL,
           not_sig = NSIG, # Number of clumped SNPs that are not significant ( p > 0.05 )
           sig_p05 = S05, # Number of clumped SNPs 0.01 < p < 0.05
           sig_p01 = S01, # Number of clumped SNPs 0.001 < p < 0.01
           sig_p001 = S001, # Number of clumped SNPs 0.0001 < p < 0.001 
           sig_p0001 = S0001, # Number of clumped SNPs p < 0.0001
           other_snps = SP2) %>%
    mutate(other_snps = gsub("\\(1\\),", ", ", other_snps),
           other_snps = gsub("\\(1\\)", "", other_snps),
           other_snps = replace(other_snps, other_snps == "NONE", NA)) %>%
    select(-CHR, -F, -BP) 
  
  SNPs <- apply(clumps, 1, function(x) {
    res <- c(x[1], strsplit(x[9], split = ", ")[[1]])
    res[!is.na(res)]
  })
  
  clumps$FBIDs <- lapply(SNPs, function(x) {
    focal <- tbl(db, "variants") %>% filter(SNP %in% x) %>% collect()
    if(nrow(focal) == 0) return(NA)
    focal %>% pull(FBID) %>% unique() %>% paste0(collapse = ", ")
    }) %>% unlist()
  
  clumps$genes <- lapply(clumps$FBIDs, function(x) {
    if(is.na(x)) return(NA)
    FB <- strsplit(x, split = ", ")[[1]]
    return(tbl(db, "genes") %>% filter(FBID %in% FB) %>% pull(gene_name) %>% paste0(collapse = ", "))
  }) %>% unlist()
  
  write_tsv(clumps, file_name)
  unlink("data/derived/plink.log")
}

lapply(c("female_early_lmm", "female_late_lmm", "male_early_lmm", "male_late_lmm", "all_four_traits"), do_snp_clumping)
```





<!-- ## Run Bayesian Sparse Linear Mixed Models -->

<!-- Here is a screenshot from the relevant part of the GEMMA manual, explaining how the BSLMMs work, and the key parameters that are estimated: -->

<!-- !["Screenshot from the GEMMA manual"](data/input/GEMMA_manual_screenshot.png) -->

<!-- I run these with a burn-in period of 50,000 iterations, then 10m sampling iterations, recording every 1000^{th} iteration. This may seem extreme, but I picked it because there was massive auto-correlation in the MCMC chain with the default settings. -->

<!-- Glossary of abbreviations and parameters used by GEMMA: -->
<!--  - PVE: "Proportion of (phenotypic) variance explained", by the SNPs and the random effect terms together -->
<!--  - PGE: "Proportion of _genetic_ variance explained by the sparse effects terms".  -->

<!--  Useful quote from Zhou: I think you can treat both h and rho as parameters and only rely on only PVE and PGE. The result essentially says that a total 3414 SNPs explain approximately 33% of phenotypic variance (i.e. PVE=0.33). Among these 3414 SNPs, a small proportion of them (\approx 158) have relatively large effects and explain a total of 48% PVE (i.e. PGE=0.48). Although these 158 SNPs have relatively larger effects than the rest of the SNPs, their absolute effect sizes are still small. All these quantities provide a description of the genetic architecture of the phenotype, and give much more information than simply categorizing a trait into polygenic vs oligogenic.  -->


<!-- ### Female early-life fitness -->
<!-- ```{r bslmm1} -->
<!-- run_command("gemma -bfile trimmed_DGRP -maf 0.05 -n 1 -bslmm 1 -w 50000 -s 10000000 -rpace 1000 -seed 1 -o female_early_bslmm") -->
<!-- ``` -->



<!-- ```{r} -->
<!-- make_trimmed_BED <- function(phenotypes){ -->

<!--   # Define a function to add phenotype data to a .fam file, for later GWAS analysis -->
<!--   # 'phenotypes' needs to have a column called 'line' -->
<!--   add_phenotypes_to_fam <- function(filepath, phenotypes){ -->
<!--     read.delim(filepath, header = FALSE, stringsAsFactors = FALSE) %>%  -->
<!--       select(V1, V2, V3, V4, V5) %>% # Get all the non-phenotype columns -->
<!--       left_join(phenotypes,  -->
<!--                 by = c("V1" = "line")) %>% -->
<!--       write.table(file = filepath,  -->
<!--                   col.names = FALSE, row.names = FALSE,  -->
<!--                   quote = FALSE, sep = "\t") -->
<!--   } -->


<!-- #  if(file.exists("data/derived/trimmed_DGRP.bed")) return(NULL) -->

<!--   # Load the BED/BIM/FAM files as a bigsnp object -->
<!--   bigsnp <- snp_readBed("data/input/dgrp2.bed", backingfile = tempfile()) -->
<!--   bigsnp_attached <- snp_attach(bigsnp) -->

<!--   ###################################################### -->
<!--   # 1. Perform simple SNP quality control using PLINK -->
<!--   ###################################################### -->
<!--   bedfile <- "data/input/dgrp2.bed" -->

<!--   plink <- download_plink() -->
<!--   bigsnp <- snp_plinkQC(plink.path = plink, -->
<!--                         prefix.in = "data/input/dgrp2", -->
<!--                         prefix.out = tempfile(), -->
<!--                         maf = 0.05, # MAF >= 0.05 -->
<!--                         geno = 0.05,   # acceptable number missing genotypes per locus: none -->
<!--                         mind = 0.1,   # acceptable proportion of missing genotypes per individual (i.e. DGRP line): none -->
<!--                         hwe = 0,    # do not filter by HWE test p-value (p = 0 is kept) -->
<!--                         autosome.only = FALSE) # Keep X chromosome -->
<!--   bigsnp <- snp_readBed(bigsnp) -->
<!--   bigsnp_attached <- snp_attach(bigsnp) -->
<!--   ###### Important messages from this QC: ######## -->
<!--   # Total genotyping rate is 0.956183. -->
<!--   # 1050867 variants removed due to missing genotype data (--geno). -->
<!--   # 2266579 variants removed due to minor allele threshold(s) -->
<!--   # (--maf/--max-maf/--mac/--max-mac). -->
<!--   # 1120981 variants and 193 people pass filters and QC. -->


<!--   # cull the PLINK files to just the DGRP lines that we measured -->
<!--   focal.lines <- phenotypes$line %>% as.character() -->
<!--   bigsnp_attached <- subset(bigsnp_attached,  -->
<!--                             ind.row = bigsnp_attached$fam$family.ID %in% focal.lines) %>% -->
<!--     snp_attach() -->

<!--   beagle <- download_beagle() -->


<!--   # Delete these files, because snp_writeBed() throws an error rather than over-writing -->
<!--   unlink(c("data/derived/dgrp2_after_QC.bed",  -->
<!--            "data/derived/dgrp2_after_QC.bim", "data/derived/dgrp2_after_QC.fam"))  -->

<!--   # Write the QC'd BED files for all 205 DGRP lines to disk -->
<!--   # This is is needed to use PLINK on them, and also because we now have a SNP set that is not pruned for LD -->
<!--   snp_writeBed(bigsnp_attached, "data/derived/dgrp2_after_QC.bed") -->

<!--   # Add our phenotype data to this new .fam file -->
<!--   add_phenotypes_to_fam("data/derived/dgrp2_after_QC.fam",  -->
<!--                         phenotypes %>% select(-block)) -->

<!--   ################################################################## -->
<!--   # 2. Remove SNPs that do not have MAF < 0.05 within our 115 lines -->
<!--   ################################################################## -->

<!--   bigsnp <- snp_plinkQC(plink.path = plink, -->
<!--                         prefix.in = "data/derived/dgrp2_after_QC", -->
<!--                         prefix.out = tempfile(), -->
<!--                         maf = 0.05, -->
<!--                         geno = 0, -->
<!--                         mind = 1, -->
<!--                         hwe = 0, -->
<!--                         autosome.only = FALSE) -->
<!--   bigsnp_attached <- snp_readBed(bigsnp) %>% snp_attach() -->
<!--   # unlink(temp.file) -->
<!--   ##### PLINK messages: ###### -->
<!--   # 1637 variants removed due to minor allele threshold(s) -->
<!--   # (--maf/--max-maf/--mac/--max-mac). -->
<!--   # 12954 variants and 115 people pass filters and QC. -->

<!--   ################################################################## -->
<!--   # 3. Perform short-range SNP clumping, using snp_clumping function -->
<!--   ################################################################## -->

<!--   # Sum the significant correlations of each SNP to each other SNP -->
<!--   summed_correlations <- apply(snp_cor(bigsnp_attached$genotypes), 1, sum) %>% -->
<!--     round(2) -->

<!--   # Identify 1 SNP from each 'clump' of highly linked SNPs -->
<!--   # Nearby SNPs that are correlated with a squared-corr of at least .1, i.e. r = +/- 0.316, are counted as clumped -->
<!--   snp_clumps <- snp_clumping(G = bigsnp_attached$genotypes,  -->
<!--                              infos.chr = bigsnp_attached$map$chromosome,  -->
<!--                              thr.r2 = 0.2, -->
<!--                              size = 1000, # 1kB windows -->
<!--                              is.size.in.bp = TRUE, -->
<!--                              infos.pos = bigsnp_attached$map$physical.pos)  -->
<!--   # After this there are 7523 SNPs left -->

<!--   clumped_subset <- subset(bigsnp_attached, ind.col = snp_clumps) %>% snp_attach() -->


<!--   ###################################################### -->
<!--   # 4. Perform long-range LD pruning using snp_autoSVD -->
<!--   ###################################################### -->
<!--   SVD_output <- snp_autoSVD(G = clumped_subset$genotypes, -->
<!--                             infos.chr = clumped_subset$map$chromosome, -->
<!--                             infos.pos = clumped_subset$map$physical.pos, -->
<!--                             thr.r2 = 0.2) -->

<!--   # Vector of SNP IDs to keep -->
<!--   SVD_output <- attributes(SVD_output)$subset -->
<!--   # After this there are 6897 SNPs left -->

<!--   # Retain all the SNPs that passed both types of clumping -->
<!--   to.keep <- snp_clumps[SVD_output] -->
<!--   clumped_subset2 <- subset(bigsnp_attached, ind.col = to.keep) %>% snp_attach() -->
<!--   summed_correlations <- data.frame(id = clumped_subset2$map$marker.ID, -->
<!--                                     summed_corr = summed_correlations[to.keep]) -->

<!--   # Delete these files, because snp_writeBed() throws an error rather than over-writing -->
<!--   unlink(c("data/derived/trimmed_DGRP.bed",  -->
<!--            "data/derived/trimmed_DGRP.bim", "data/derived/trimmed_DGRP.fam"))  -->

<!--   # Save the fully-pruned SNP data, and the SNP "tagging" data -->
<!--   snp_writeBed(clumped_subset2, "data/derived/trimmed_DGRP.bed") -->
<!--   write.csv(summed_correlations, "data/derived/summed_interSNP_correlations.csv", row.names = FALSE) -->

<!--   # Lastly, add our phenotype data to the new .fam file -->
<!--   add_phenotypes_to_fam("data/derived/trimmed_DGRP.fam",  -->
<!--                         phenotypes %>% select(-block)) -->
<!-- } -->
<!-- make_trimmed_BED(phenotypes = predicted_line_means) -->

<!-- if(file.exists('data/derived/trimmed_DGRP.bk')) unlink('data/derived/trimmed_DGRP.bk') -->
<!-- dgrp_bed <- snp_readBed("data/derived/trimmed_DGRP.bed") %>% snp_attach() -->
<!-- ``` -->


